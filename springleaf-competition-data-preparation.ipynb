{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"In this kernel I just load the competition data, clean it using pre-stored information from the \"Springleaf competition : EDA\" kernel and save the results. The results are to be used in script that build different classificaiton models."},{"metadata":{"trusted":true,"_uuid":"82988a0c4737e758ace4e64de772cb60372c1428"},"cell_type":"code","source":"train_df = pd.read_csv('../input/springleaf-marketing-response/train.csv')\ntest_df = pd.read_csv('../input/springleaf-marketing-response//test.csv')\ntrain_orig_shape = train_df.shape\ntest_orig_shape = test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"272e24aa67fd6ce5e09753631d6d21cd30fba869"},"cell_type":"code","source":"data = [train_df, test_df]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d8cf00d08afd3479288608c36147eec038f1b41"},"cell_type":"code","source":"prep_data = np.load('../input/springleaf-competition-eda/prep_info.npz')\nmissing_to_remove, missing_to_fill, missing_example_to_remove, constants, duplicates, dates, potential_to_remove = \\\n    prep_data[\"arr_0\"], prep_data[\"arr_1\"], prep_data[\"arr_2\"], prep_data[\"arr_3\"], prep_data[\"arr_4\"], prep_data[\"arr_5\"], prep_data[\"arr_7\"]\ntype(potential_to_remove)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e61f6bc669cb0098d40e7cdbfedcc790a0b4ada1"},"cell_type":"markdown","source":"Clearing features in missing_to_remove, constants and duplicates"},{"metadata":{"trusted":true,"_uuid":"b0ecab85e19b8dfa503b24d80f2235ca1c39b3b6"},"cell_type":"code","source":"for df in data:\n    df.drop(np.concatenate((missing_to_remove, constants, duplicates)), axis=1, inplace=True)\ndata[0].shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8976b878430ec9a904c68ef54a3958db21289dad"},"cell_type":"markdown","source":"Dealing with the rest of missing data:"},{"metadata":{"trusted":true,"_uuid":"047bd2307a30ee93e357eb93059e2257470f7f9f"},"cell_type":"code","source":"# updating missing_to_fill and missing_to_remove\nmissing_to_fill = [feat for feat in missing_to_fill if feat not in np.concatenate((missing_to_remove, constants, duplicates))]\n\n# separating categorical and numerical features since these are treated differently\ncategorical = train_df.select_dtypes(include=[np.object]).columns\nnumerical = train_df.select_dtypes(include=[np.number]).columns\n\n# filling in the missing data for features containing many of them\nfor df in data:\n    for col in missing_to_fill:\n        try:\n            if col in categorical:\n                # fill missing data with mode\n                df[col].fillna(df[col].mode()[0], inplace=True)\n            else:\n                # fill missing data with mean\n                df[col].fillna(df[col].mean(), inplace=True)\n        except KeyError:\n            print(\"Feature {} has already been removed!\".format(col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d74af154b3acd860fc3ab0bc5933ca3ff3b4bad"},"cell_type":"code","source":"# removing rows with missing data in the training data, but filling those in test data\ndata[0].dropna(axis=0, inplace=True)\nmissing_examples_to_remove = [feat for feat in data[1].columns if data[1][feat].isnull().sum() > 0]\nfor col in missing_examples_to_remove:\n    try:\n        if col in categorical:\n            # fill missing data with mode\n            test_df[col].fillna(data[0][col].mode()[0], inplace=True)\n        else:\n            # fill missing data with mean\n            test_df[col].fillna(data[0][col].mean(), inplace=True)\n    except KeyError:\n        print(\"Feature {} has already been removed!\".format(col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78680af29be4cf06da089e91f2fa74dd23c24b51"},"cell_type":"code","source":"# making sure there are no more missing entries\ntrain_cleared_shape = data[0].shape\ntest_cleared_shape = data[1].shape\ndata[0].isnull().sum().max(), data[1].isnull().sum().max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a5067d2550b2a25c63f32e634146ec56ea9cc60"},"cell_type":"code","source":"train_cleared_shape, test_cleared_shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5445b699dc1c02660c7255458d3ba36dbaebdfe3"},"cell_type":"markdown","source":"Encoding categorical data, for now we use simple integer encoding instead of one-hot encoding, we may need to come back to this later"},{"metadata":{"trusted":true,"_uuid":"cdfaa9049ebf4b2414f2a22161065b26f80ade5a"},"cell_type":"code","source":"from datetime import datetime\nyear_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).year\nmonth_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).month\nday_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).day\nhour_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).hour\nminute_func = lambda x: datetime.strptime(x, \"%d%b%y:%H:%M:%S\" ).minute\n\n# we perform the encoding inplace because of limited RAM\nfor i in range(len(data)):\n    for col in categorical:\n        if col in dates:\n            data[i][col + '_year'] = data[i][col].map(year_func)\n            data[i][col + '_month'] = data[i][col].map(month_func)\n            data[i][col + '_day'] = data[i][col].map(day_func)\n            data[i][col + '_hour'] = data[i][col].map(hour_func)\n            data[i][col + '_minute'] = data[i][col].map(minute_func)\n        data[i][col] = data[i][col].factorize()[0]\ntrain_encod_shape = data[0].shape\ntest_encod_shape = data[1].shape\ndata[0].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55207cd58dad3f8155e3073be3ac61467a6fc510"},"cell_type":"code","source":"train_encod_shape, test_encod_shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adf1459aa73b0df9fb73653ceeabc6105c5fa5c4"},"cell_type":"markdown","source":"Saving data, also saving a smaller chunk of it for rapid prototyping of models"},{"metadata":{"trusted":true,"_uuid":"d79fefdefaeda2dde2527f3ad3d016747ec27da6"},"cell_type":"code","source":"data[0].to_csv('train_clean.csv')\ndata[1].to_csv('test_clean.csv')\ndata[0].sample(frac=0.2).to_csv('train_clean_small.csv')\ndata[1].sample(frac=0.2).to_csv('test_clean_small.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47075b3373673b13fee8fc4dc38f63a2d9cc0084"},"cell_type":"code","source":"print(\"Shape of training data:\")\nprint(\"Original : {}    After cleaning: {}    After encoding: {}\".format(train_orig_shape, train_cleared_shape, train_encod_shape))\nprint(\"Shape of test data:\")\nprint(\"Original : {}    After cleaning: {}    After encoding: {}\".format(test_orig_shape, test_cleared_shape, test_encod_shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c41c4a1af93bc67fb1ef37748cc7592591c51d0d"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"202d647816a05c0d87e45d78813f37133defb906"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}